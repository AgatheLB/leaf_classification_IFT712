\section{Conclusion et pistes de recherche future}
Notre équipe a pu développer un gestionnaire de classifieurs ainsi que leur implémentation propre. Il permet de faire une recherche d'hyper-paramètres permettant de maximiser le score de justesse du modèle. 
Celui-ci permettrait alors d'effectuer la classification des feuilles végétales présentes dans l'ensemble de données \emph{leaf-classification} que l'on retrouve sur le site web \textbf{kaggle}.

En rétrospective, la plupart des modèles présentent de bonnes performances, avec souvent une justesse de 100\% pour l'entraînement et majoritairement au-delà des 95\% pour la validation. On dénote tout de même que les trois modèles les plus performants selon leur justesse de validation sont: \emph{Random Forest}(98.48\%), \emph{LDA}(97.98\%) et \emph{KNN}(97.47\%).\linebreak 

Une approche plus globale pourrait être envisagée afin d'obtenir des modèles plus performants avec une combinaison de modèles de classification. Chaque modèle serait entraîné séparemment puis sauvegardé. Pour les prédictions, un vote serait alors effectué entre les différents modèles afin d'établir la prédiction majoritaire. 
Pour le choix des modèles de classification à combiner, nous pourrions utiliser le même modèle selon différents hyper-paramètres. 
Afin d'avoir une combinaison de modèles la plus performante possible, des stratégies de \emph{bagging} et \emph{boosting} pourraient être utilisées selon le type de modèles utilisés (tendance à sur ou sous-apprendre).